{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 19:53:58.187912: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from dnn_tau import Dnn_tau\n",
    "import sys\n",
    "sys.path.append('./utils/')\n",
    "from DD_data_extractor_git import Data_extractor_v4, output_vars_v4, normalize, bucketize, split_dataset2, flatten_2D_list\n",
    "import os\n",
    "import fnmatch\n",
    "# from utils import \n",
    "from copy import deepcopy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/hnl/prompt_tau/anatuple/nanoV10/TEST10/\"\n",
    "features = deepcopy(output_vars_v4)\n",
    "features.extend(['signal_label', 'channel', 'event_type', 'mass_hyp'])\n",
    "# channels = os.listdir(path)\n",
    "channels = ['tee', 'tem', 'tmm', 'tte', 'ttm']\n",
    "relative_path = \"/anatuple/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "flat_features = flatten_2D_list(features)\n",
    "for i in range(len(flat_features)):\n",
    "    values.append([])\n",
    "data = dict(zip(flat_features, values))\n",
    "\n",
    "for channel in channels:\n",
    "    extractor = Data_extractor_v4(channel)\n",
    "    data = extractor(path+channel+relative_path, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data_dict)\n",
    "data = data.rename(columns={\"genWeight\": \"weightOriginal\"})\n",
    "weightNorm = deepcopy(data['weightOriginal'])\n",
    "data['weightNorm'] = weightNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['event', 'weightOriginal', 'charge_1', 'charge_2', 'charge_3', 'pt_1', 'pt_2', 'pt_3', 'pt_MET', 'eta_1', 'eta_2', 'eta_3', 'mass_1', 'mass_2', 'mass_3', 'deltaphi_12', 'deltaphi_13', 'deltaphi_23', 'deltaphi_1MET', 'deltaphi_2MET', 'deltaphi_3MET', 'deltaphi_1(23)', 'deltaphi_2(13)', 'deltaphi_3(12)', 'deltaphi_MET(12)', 'deltaphi_MET(13)', 'deltaphi_MET(23)', 'deltaphi_1(2MET)', 'deltaphi_1(3MET)', 'deltaphi_2(1MET)', 'deltaphi_2(3MET)', 'deltaphi_3(1MET)', 'deltaphi_3(2MET)', 'deltaeta_12', 'deltaeta_13', 'deltaeta_23', 'deltaeta_1(23)', 'deltaeta_2(13)', 'deltaeta_3(12)', 'deltaR_12', 'deltaR_13', 'deltaR_23', 'deltaR_1(23)', 'deltaR_2(13)', 'deltaR_3(12)', 'pt_123', 'mt_12', 'mt_13', 'mt_23', 'mt_1MET', 'mt_2MET', 'mt_3MET', 'mt_1(23)', 'mt_2(13)', 'mt_3(12)', 'mt_MET(12)', 'mt_MET(13)', 'mt_MET(23)', 'mt_1(2MET)', 'mt_1(3MET)', 'mt_2(1MET)', 'mt_2(3MET)', 'mt_3(1MET)', 'mt_3(2MET)', 'mass_12', 'mass_13', 'mass_23', 'mass_123', 'Mt_tot', 'HNL_CM_angle_with_MET_1', 'HNL_CM_angle_with_MET_2', 'W_CM_angle_to_plane_1', 'W_CM_angle_to_plane_2', 'W_CM_angle_to_plane_with_MET_1', 'W_CM_angle_to_plane_with_MET_2', 'HNL_CM_mass_1', 'HNL_CM_mass_2', 'HNL_CM_mass_with_MET_1', 'HNL_CM_mass_with_MET_2', 'W_CM_angle_12', 'W_CM_angle_13', 'W_CM_angle_23', 'W_CM_angle_1MET', 'W_CM_angle_2MET', 'W_CM_angle_3MET', 'n_tauh', 'mass_hyp', 'signal_label', 'channel', 'event_type', 'weightNorm']\n",
      "{'ttm': 0}\n"
     ]
    }
   ],
   "source": [
    "N = len(data['event'])\n",
    "data_norm = normalize(pd.DataFrame(data), 'mass_hyp', N, weight_name='weightNorm')\n",
    "data_norm = normalize(data_norm, 'signal_label', N, weight_name='weightNorm')\n",
    "data_norm = normalize(data_norm, 'channel', N/5, weight_name='weightNorm')\n",
    "data_processed, channel_indices = bucketize(data_norm, 'channel')\n",
    "print(list(data_processed.keys()))\n",
    "print(channel_indices)\n",
    "# print(N)\n",
    "# print(sum(data_processed['weightNorm']))\n",
    "# print(data_processed['weightNorm'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ddemler/HNLclassifier\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "output_dir = os.path.join(current_dir,\"saved_files\", \"extracted_data\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data_processed.to_pickle(output_dir + \"/TEST10_data_Aug3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['charge_1', 'charge_2', 'charge_3', 'pt_1', 'pt_2', 'pt_3', 'pt_MET', 'eta_1', 'eta_2', 'eta_3', 'mass_1', 'mass_2', 'mass_3', 'deltaphi_12', 'deltaphi_13', 'deltaphi_23', 'deltaphi_1MET', 'deltaphi_2MET', 'deltaphi_3MET', 'deltaphi_1(23)', 'deltaphi_2(13)', 'deltaphi_3(12)', 'deltaphi_MET(12)', 'deltaphi_MET(13)', 'deltaphi_MET(23)', 'deltaphi_1(2MET)', 'deltaphi_1(3MET)', 'deltaphi_2(1MET)', 'deltaphi_2(3MET)', 'deltaphi_3(1MET)', 'deltaphi_3(2MET)', 'deltaeta_12', 'deltaeta_13', 'deltaeta_23', 'deltaeta_1(23)', 'deltaeta_2(13)', 'deltaeta_3(12)', 'deltaR_12', 'deltaR_13', 'deltaR_23', 'deltaR_1(23)', 'deltaR_2(13)', 'deltaR_3(12)', 'pt_123', 'mt_12', 'mt_13', 'mt_23', 'mt_1MET', 'mt_2MET', 'mt_3MET', 'mt_1(23)', 'mt_2(13)', 'mt_3(12)', 'mt_MET(12)', 'mt_MET(13)', 'mt_MET(23)', 'mt_1(2MET)', 'mt_1(3MET)', 'mt_2(1MET)', 'mt_2(3MET)', 'mt_3(1MET)', 'mt_3(2MET)', 'mass_12', 'mass_13', 'mass_23', 'mass_123', 'Mt_tot', 'HNL_CM_angle_with_MET_1', 'HNL_CM_angle_with_MET_2', 'W_CM_angle_to_plane_1', 'W_CM_angle_to_plane_2', 'W_CM_angle_to_plane_with_MET_1', 'W_CM_angle_to_plane_with_MET_2', 'HNL_CM_mass_1', 'HNL_CM_mass_2', 'HNL_CM_mass_with_MET_1', 'HNL_CM_mass_with_MET_2', 'W_CM_angle_12', 'W_CM_angle_13', 'W_CM_angle_23', 'W_CM_angle_1MET', 'W_CM_angle_2MET', 'W_CM_angle_3MET', 'mass_hyp', 'signal_label']\n"
     ]
    }
   ],
   "source": [
    "selection=list(data_processed.keys())\n",
    "remove_fromselection= ['n_tauh', 'event_type', 'event', 'weightOriginal', 'weightNorm', 'channel']\n",
    "\n",
    "for i in remove_fromselection:\n",
    "       selection.remove(i)\n",
    "\n",
    "print(selection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of events :  248415\n",
      "Train set : 50.00 %\n",
      "Validation set : 10.00 %\n",
      "Test set : 40.00 %\n"
     ]
    }
   ],
   "source": [
    "train, val, test = split_dataset2(data_processed)\n",
    "pd.to_pickle(train, output_dir + \"/TEST10_train_aug3\")\n",
    "pd.to_pickle(val, output_dir +\"/TEST10_val_aug3\")\n",
    "pd.to_pickle(test,output_dir +  \"/TEST10_test_aug3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
