models:
  - name: Model1
    loss_function: normal  
    patience: 30                   
    hidden_layers: [16,26,32,32,32,48,52,48,32,32,32,26]
    activation_function: tanh  
    learning_rate: 0.001         

  - name: Model2
    loss_function: no_mse
    patience: 30
    hidden_layers: [16,26,32,32,32,48,52,48,32,32,32,26]
    activation_function: tanh
    learning_rate: 0.0005

  - name: Model3
    loss_function: no_mse
    patience: 30
    hidden_layers: [16,26,32,32,42,48,52,64,64,64,64,64,64,64,64,64,50,32]
    activation_function: tanh
    learning_rate: 0.0005
  
  - name: Model4
    loss_function: normal
    patience: 30
    hidden_layers: [16,26,32,32,42,48,52,64,64,64,64,64,64,64,64,64,50,32]
    activation_function: tanh
    learning_rate: 0.0005