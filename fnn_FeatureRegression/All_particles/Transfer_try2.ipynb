{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 112\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "# from fnn_datagenerator import BatchedFakeParticleDataset_All, flat_output_vars\n",
    "from m5 import CustomKinematicNet, activation, hidden_layers, dfpath, modelsavepath, flat_output_vars, train_batch_size, prefix\n",
    "from fnn_datagenerator import flat_output_vars, GeV_outputvars\n",
    "\n",
    "import os\n",
    "import sys\n",
    "#os add to path /home/ddemler/HNLclassifier/DNN/\n",
    "sys.path.append('/home/ddemler/HNLclassifier/DNN/')\n",
    "from pytorch2python import create_data_loaders, create_test_loader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append('/home/ddemler/HNLclassifier/SignificancePlotting/')\n",
    "sys.path.append('/home/ddemler/HNLclassifier/utils/')\n",
    "\n",
    "from Significance_func import *\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodelsavepath='/home/ddemler/HNLclassifier/saved_files/transfer_lmodel/Aug29/' + prefix + '_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_basepath='/home/ddemler/HNLclassifier/saved_files/extracted_data/TEST10_'\n",
    "# TEST10_data_newAug28\n",
    "fulldatapath=data_basepath + 'train_Aug29'\n",
    "valdatapath=data_basepath + 'val_Aug29'\n",
    "testdatapath=data_basepath + 'test_Aug29'\n",
    "\n",
    "fulldata=pd.read_pickle(fulldatapath)\n",
    "valdata=pd.read_pickle(valdatapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['event', 'weightOriginal', 'charge_1', 'charge_2', 'charge_3', 'pt_1', 'pt_2', 'pt_3', 'pt_MET', 'eta_1', 'eta_2', 'eta_3', 'mass_1', 'mass_2', 'mass_3', 'phi_1', 'phi_2', 'phi_3', 'phi_MET', 'deltaphi_12', 'deltaphi_13', 'deltaphi_23', 'deltaphi_1MET', 'deltaphi_2MET', 'deltaphi_3MET', 'deltaphi_1(23)', 'deltaphi_2(13)', 'deltaphi_3(12)', 'deltaphi_MET(12)', 'deltaphi_MET(13)', 'deltaphi_MET(23)', 'deltaphi_1(2MET)', 'deltaphi_1(3MET)', 'deltaphi_2(1MET)', 'deltaphi_2(3MET)', 'deltaphi_3(1MET)', 'deltaphi_3(2MET)', 'deltaeta_12', 'deltaeta_13', 'deltaeta_23', 'deltaeta_1(23)', 'deltaeta_2(13)', 'deltaeta_3(12)', 'deltaR_12', 'deltaR_13', 'deltaR_23', 'deltaR_1(23)', 'deltaR_2(13)', 'deltaR_3(12)', 'pt_123', 'mt_12', 'mt_13', 'mt_23', 'mt_1MET', 'mt_2MET', 'mt_3MET', 'mt_1(23)', 'mt_2(13)', 'mt_3(12)', 'mt_MET(12)', 'mt_MET(13)', 'mt_MET(23)', 'mt_1(2MET)', 'mt_1(3MET)', 'mt_2(1MET)', 'mt_2(3MET)', 'mt_3(1MET)', 'mt_3(2MET)', 'mass_12', 'mass_13', 'mass_23', 'mass_123', 'Mt_tot', 'HNL_CM_angle_with_MET_1', 'HNL_CM_angle_with_MET_2', 'HNL_CM_angle_with_MET_3', 'W_CM_angle_to_plane_1', 'W_CM_angle_to_plane_2', 'W_CM_angle_to_plane_3', 'W_CM_angle_to_plane_with_MET_1', 'W_CM_angle_to_plane_with_MET_2', 'W_CM_angle_to_plane_with_MET_3', 'HNL_CM_mass_1', 'HNL_CM_mass_2', 'HNL_CM_mass_3', 'HNL_CM_mass_with_MET_1', 'HNL_CM_mass_with_MET_2', 'HNL_CM_mass_with_MET_3', 'W_CM_angle_12', 'W_CM_angle_13', 'W_CM_angle_23', 'W_CM_angle_1MET', 'W_CM_angle_2MET', 'W_CM_angle_3MET', 'n_tauh', 'px_1', 'py_1', 'pz_1', 'E_1', 'px_2', 'py_2', 'pz_2', 'E_2', 'px_3', 'py_3', 'pz_3', 'E_3', 'moth_mass_12', 'moth_mass_13', 'moth_mass_23', 'moth_pt_12', 'moth_pt_13', 'moth_pt_23', 'moth_eta_12', 'moth_eta_13', 'moth_eta_23', 'moth_phi_12', 'moth_phi_13', 'moth_phi_23', 'moth_px_12', 'moth_px_13', 'moth_px_23', 'moth_py_12', 'moth_py_13', 'moth_py_23', 'moth_pz_12', 'moth_pz_13', 'moth_pz_23', 'moth_E_12', 'moth_E_13', 'moth_E_23', 'E_tot', 'mass_hyp', 'signal_label', 'channel', 'event_type', 'weightNorm']\n"
     ]
    }
   ],
   "source": [
    "realdata_allvars = list(fulldata.columns)\n",
    "print(realdata_allvars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "inputdata shape:  torch.Size([124208, 14])\n",
      "outputdata shape:  torch.Size([124208, 112])\n",
      "val inputdata shape:  torch.Size([24841, 14])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# old_model_input= ['1_eta', '1_mass', '1_phi', '1_pt', '2_eta?', '2_mass', '2_phi', '2_pt', '3_eta', '3_mass', '3_phi', '3_pt', 'MET_phi', 'MET_pt']\n",
    "renamed_old_input_names=['eta_1', 'mass_1', 'phi_1', 'pt_1', 'eta_2', 'mass_2', 'phi_2', 'pt_2', 'eta_3', 'mass_3', 'phi_3', 'pt_3', 'phi_MET', 'pt_MET']\n",
    "additionalinput_vars=['charge_1', 'charge_2', 'charge_3', 'channel','n_tauh', 'mass_hyp']\n",
    "output=fulldata['signal_label']\n",
    "\n",
    "\n",
    "\n",
    "def datamaker(data):\n",
    "    outputdata_shape= (len(data['pt_MET']), len(flat_output_vars))\n",
    "    inputdata_shape= (len(data['pt_MET']), len(renamed_old_input_names))\n",
    "\n",
    "    inputdata=np.empty(inputdata_shape)\n",
    "    outputdata=np.empty(outputdata_shape)\n",
    "\n",
    "    for i, outvar in enumerate(flat_output_vars):\n",
    "        if outvar in GeV_outputvars:\n",
    "            outputdata[:,i]=data[outvar]/data['E_tot']\n",
    "        else:\n",
    "            outputdata[:,i]=data[flat_output_vars[i]]\n",
    "\n",
    "    for i in range(len(renamed_old_input_names)):\n",
    "        inputdata[:,i]=data[renamed_old_input_names[i]]\n",
    "\n",
    "    input_tensor = torch.tensor(inputdata, dtype=torch.float32)\n",
    "    output_tensor = torch.tensor(outputdata, dtype=torch.float32)\n",
    "\n",
    "    return input_tensor, output_tensor\n",
    "\n",
    "def additional_datamaker(data):\n",
    "    outputdata_shape = (len(data['pt_MET']), 1)\n",
    "    inputdata_shape = (len(data['pt_MET']), len(additionalinput_vars))\n",
    "\n",
    "    inputdata = np.empty(inputdata_shape)\n",
    "    outputdata = np.empty(outputdata_shape)\n",
    "\n",
    "    for i, outvar in enumerate(additionalinput_vars):\n",
    "        inputdata[:, i] = data[outvar]\n",
    "    outputdata[:,0]=data['signal_label']\n",
    "\n",
    "    input_tensor = torch.tensor(inputdata, dtype=torch.float32)\n",
    "    output_tensor = torch.tensor(outputdata, dtype=torch.float32)\n",
    "\n",
    "    return input_tensor, output_tensor\n",
    "    \n",
    "train_weight=fulldata['weightNorm'].to_numpy()\n",
    "val_weight=valdata['weightNorm'].to_numpy()\n",
    "\n",
    "print(type(train_weight))\n",
    "\n",
    "train_weight_tensor=torch.tensor(train_weight, dtype=torch.float32)\n",
    "val_weight_tensor=torch.tensor(val_weight, dtype=torch.float32)\n",
    "\n",
    "\n",
    "train_inputdata, train_outputdata=datamaker(fulldata)\n",
    "val_inputdata, val_outputdata=datamaker(valdata)\n",
    "\n",
    "ad_train_inputdata, ad_train_outputdata=additional_datamaker(fulldata)\n",
    "ad_val_inputdata, ad_val_outputdata=additional_datamaker(valdata)\n",
    "\n",
    "train_inputfull=torch.cat((train_inputdata, ad_train_inputdata), dim=1)\n",
    "val_inputfull=torch.cat((val_inputdata, ad_val_inputdata), dim=1)\n",
    "\n",
    "print(\"inputdata shape: \", train_inputdata.shape)\n",
    "print(\"outputdata shape: \", train_outputdata.shape)\n",
    "print(\"val inputdata shape: \", val_inputdata.shape)\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model= CustomKinematicNet(input_size=14, hidden_layers=hidden_layers, lenoutput=len(flat_output_vars), activation_fn=activation)\n",
    "pretrained_model.load_state_dict(torch.load(modelsavepath))\n",
    "# pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.pretrained = pretrained_model\n",
    "        self.pretrained.layers = self.pretrained.layers[:-1]  # Remove the last layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pretrained(x)\n",
    "\n",
    "\n",
    "feature_extractor = FeatureExtractor(pretrained_model=pretrained_model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferCustomKinematicNet(nn.Module):\n",
    "    def __init__(self, feature_extractor, additional_input_size, new_hidden_layers):\n",
    "        super(TransferCustomKinematicNet, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = feature_extractor\n",
    "        \n",
    "        # Freeze the pre-trained layers\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Define new hidden layers\n",
    "        input_size = feature_extractor.pretrained.layers[-1].out_features + additional_input_size\n",
    "        layer_sizes = [input_size] + new_hidden_layers + [1]  # Final output size is 1 for binary classification\n",
    "        \n",
    "        self.new_layers = nn.ModuleList()\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            self.new_layers.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
    "        \n",
    "        self.activation_fn = nn.ReLU()\n",
    "        self.output_activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, additional_input):\n",
    "        features = self.feature_extractor(x)\n",
    "        combined_input = torch.cat((features, additional_input), dim=-1)\n",
    "        \n",
    "        out = combined_input\n",
    "        for i in range(len(self.new_layers) - 1):\n",
    "            out = self.activation_fn(self.new_layers[i](out))\n",
    "        \n",
    "        out = self.output_activation(self.new_layers[-1](out))\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransferCustomKinematicNet(\n",
       "  (feature_extractor): FeatureExtractor(\n",
       "    (pretrained): CustomKinematicNet(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=14, out_features=512, bias=True)\n",
       "        (1-2): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        (3): Linear(in_features=526, out_features=512, bias=True)\n",
       "        (4-5): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        (6): Linear(in_features=526, out_features=512, bias=True)\n",
       "        (7-8): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        (9): Linear(in_features=526, out_features=512, bias=True)\n",
       "        (10-11): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        (12): Linear(in_features=526, out_features=512, bias=True)\n",
       "        (13-14): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        (15): Linear(in_features=526, out_features=512, bias=True)\n",
       "        (16-17): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        (18): Linear(in_features=526, out_features=512, bias=True)\n",
       "        (19-20): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        (21): Linear(in_features=526, out_features=512, bias=True)\n",
       "        (22-23): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        (24): Linear(in_features=526, out_features=512, bias=True)\n",
       "        (25-26): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        (27): Linear(in_features=526, out_features=512, bias=True)\n",
       "        (28): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (new_layers): ModuleList(\n",
       "    (0): Linear(in_features=518, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (activation_fn): ReLU()\n",
       "  (output_activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_inputfull, ad_train_outputdata, train_weight_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=320, shuffle=True)\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(val_inputfull, ad_val_outputdata, val_weight_tensor)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=320, shuffle=False)\n",
    "\n",
    "# Initialize the feature extractor with the pre-trained model\n",
    "feature_extractor = FeatureExtractor(pretrained_model=pretrained_model)\n",
    "\n",
    "# Initialize the new model\n",
    "# Assuming YOUR_ADDITIONAL_INPUT_SIZE is the number of additional features you have\n",
    "new_model = TransferCustomKinematicNet(feature_extractor, additional_input_size=len(additionalinput_vars), new_hidden_layers=[128])\n",
    "new_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([], device='cuda:1', dtype=torch.int64), tensor([], device='cuda:1', dtype=torch.int64))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m new_optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     25\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m outputs \u001b[39m=\u001b[39m new_model(pretrained_input, additional_input)\n\u001b[1;32m     28\u001b[0m \u001b[39m# Compute Loss without reduction\u001b[39;00m\n\u001b[1;32m     29\u001b[0m loss_unreduced \u001b[39m=\u001b[39m criterion(outputs, target)\n",
      "File \u001b[0;32m~/.conda/envs/Dmitri-conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m, in \u001b[0;36mTransferCustomKinematicNet.forward\u001b[0;34m(self, x, additional_input)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, additional_input):\n\u001b[0;32m---> 23\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_extractor(x)\n\u001b[1;32m     24\u001b[0m     combined_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((features, additional_input), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     26\u001b[0m     out \u001b[39m=\u001b[39m combined_input\n",
      "File \u001b[0;32m~/.conda/envs/Dmitri-conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m, in \u001b[0;36mFeatureExtractor.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m----> 8\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpretrained(x)\n",
      "File \u001b[0;32m~/.conda/envs/Dmitri-conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/HNLclassifier/fnn_FeatureRegression/All_particles/m5.py:89\u001b[0m, in \u001b[0;36mCustomKinematicNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_fn(layer(torch\u001b[39m.\u001b[39mcat((x, inputs), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n\u001b[1;32m     88\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_fn(layer(x))\n\u001b[1;32m     91\u001b[0m \u001b[39m# Check if the output layer needs the original inputs\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m3\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/Dmitri-conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/Dmitri-conda/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_optimizer = torch.optim.AdamW(new_model.parameters(), lr=4e-3, weight_decay=1e-2)\n",
    "new_criterion = nn.BCELoss()\n",
    "new_scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(new_optimizer, 'min', patience=5, factor=0.3, verbose=True)\n",
    "numepochs=100\n",
    "\n",
    "\n",
    "# Binary Cross Entropy Loss for classification\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "model_patience=15\n",
    "best_valloss= np.inf\n",
    "for epoch in range(epochs):\n",
    "    new_model.train()\n",
    "    weightedfull_trainloss=0\n",
    "    for i, (combined_input, target, sample_weight) in enumerate(train_dataloader):\n",
    "        # Split the combined input into input for the pre-trained model and additional input\n",
    "        pretrained_input = combined_input[:, :train_inputdata.shape[1]].to(device)\n",
    "        additional_input = combined_input[:, train_inputdata.shape[1]:].to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        new_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = new_model(pretrained_input, additional_input)\n",
    "        \n",
    "        # Compute Loss without reduction\n",
    "        loss_unreduced = criterion(outputs, target)\n",
    "        \n",
    "        # Apply sample weights and compute the final loss\n",
    "        weighted_loss = (loss_unreduced * sample_weight.to(device)).mean()\n",
    "\n",
    "        weightedfull_trainloss += weighted_loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        weighted_loss.backward()\n",
    "        new_optimizer.step()\n",
    "    \n",
    "    weightedfull_trainloss /= len(train_dataloader.dataset)\n",
    "    new_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for i, (combined_input, target, sample_weight) in enumerate(val_dataloader):\n",
    "            # Split the combined input into input for the pre-trained model and additional input\n",
    "            pretrained_input = combined_input[:, :train_inputdata.shape[1]].to(device)\n",
    "            additional_input = combined_input[:, train_inputdata.shape[1]:].to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = new_model(pretrained_input, additional_input)\n",
    "            \n",
    "            # Compute Loss without reduction\n",
    "            loss_unreduced = criterion(outputs, target)\n",
    "            \n",
    "            # Apply sample weights and compute the final loss\n",
    "            weighted_loss = (loss_unreduced * sample_weight.to(device)).sum()\n",
    "            \n",
    "            val_loss += weighted_loss.item()\n",
    "        \n",
    "        val_loss /= len(val_dataloader.dataset)\n",
    "        \n",
    "        if val_loss < best_valloss:\n",
    "            patience=model_patience\n",
    "            best_valloss = val_loss\n",
    "            epoch_best=epoch\n",
    "            torch.save(new_model.state_dict(), newmodelsavepath)\n",
    "        else:\n",
    "            patience-=1\n",
    "            if patience==0:\n",
    "                print(\"Early stopping, saving epoch \", epoch_best)\n",
    "                break\n",
    "        \n",
    "        new_scheduler.step(val_loss)\n",
    "    \n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Train Loss: {weightedfull_trainloss:.4e}, Val Loss: {val_loss:.4e}')\n",
    "\n",
    "    # You can add code here for validation and learning rate scheduling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of column  0 : tensor(-0.1080)\n",
      "Mean of column  1 : tensor(0.7017)\n",
      "Mean of column  2 : tensor(0.0949)\n",
      "Mean of column  3 : tensor(84.2402)\n",
      "Mean of column  4 : tensor(0.0102)\n",
      "Mean of column  5 : tensor(0.6764)\n",
      "Mean of column  6 : tensor(-0.1918)\n",
      "Mean of column  7 : tensor(72.1675)\n",
      "Mean of column  8 : tensor(-0.0113)\n",
      "Mean of column  9 : tensor(0.1057)\n",
      "Mean of column  10 : tensor(0.0620)\n",
      "Mean of column  11 : tensor(79.3182)\n",
      "Mean of column  12 : tensor(0.0453)\n",
      "Mean of column  13 : tensor(98.1460)\n",
      "Mean of column  14 : tensor(0.0312)\n",
      "Mean of column  15 : tensor(0.0188)\n",
      "Mean of column  16 : tensor(0.0250)\n",
      "Mean of column  17 : tensor(0.)\n",
      "Mean of column  18 : tensor(1.8687)\n",
      "Mean of column  19 : tensor(447.3125)\n",
      "Mean of column  0 : tensor(0.0051)\n",
      "Mean of column  1 : tensor(0.7156)\n",
      "Mean of column  2 : tensor(0.0248)\n",
      "Mean of column  3 : tensor(96.7213)\n",
      "Mean of column  4 : tensor(0.0710)\n",
      "Mean of column  5 : tensor(0.7186)\n",
      "Mean of column  6 : tensor(0.0675)\n",
      "Mean of column  7 : tensor(70.7257)\n",
      "Mean of column  8 : tensor(0.0119)\n",
      "Mean of column  9 : tensor(0.1057)\n",
      "Mean of column  10 : tensor(0.1119)\n",
      "Mean of column  11 : tensor(89.3292)\n",
      "Mean of column  12 : tensor(-0.0216)\n",
      "Mean of column  13 : tensor(102.5690)\n",
      "Mean of column  14 : tensor(0.0562)\n",
      "Mean of column  15 : tensor(0.0375)\n",
      "Mean of column  16 : tensor(0.0250)\n",
      "Mean of column  17 : tensor(0.)\n",
      "Mean of column  18 : tensor(1.8563)\n",
      "Mean of column  19 : tensor(473.5625)\n",
      "Mean of column  0 : tensor(-0.0568)\n",
      "Mean of column  1 : tensor(0.7363)\n",
      "Mean of column  2 : tensor(0.1435)\n",
      "Mean of column  3 : tensor(94.7349)\n",
      "Mean of column  4 : tensor(-0.1248)\n",
      "Mean of column  5 : tensor(0.6429)\n",
      "Mean of column  6 : tensor(-0.0739)\n",
      "Mean of column  7 : tensor(67.4557)\n",
      "Mean of column  8 : tensor(-0.0620)\n",
      "Mean of column  9 : tensor(0.1057)\n",
      "Mean of column  10 : tensor(0.0374)\n",
      "Mean of column  11 : tensor(84.7038)\n",
      "Mean of column  12 : tensor(0.2931)\n",
      "Mean of column  13 : tensor(102.8832)\n",
      "Mean of column  14 : tensor(-0.0625)\n",
      "Mean of column  15 : tensor(0.1750)\n",
      "Mean of column  16 : tensor(-0.0063)\n",
      "Mean of column  17 : tensor(0.)\n",
      "Mean of column  18 : tensor(1.8625)\n",
      "Mean of column  19 : tensor(459.8438)\n",
      "Mean of column  0 : tensor(-0.0311)\n",
      "Mean of column  1 : tensor(0.7489)\n",
      "Mean of column  2 : tensor(-0.0137)\n",
      "Mean of column  3 : tensor(77.3508)\n",
      "Mean of column  4 : tensor(-0.0152)\n",
      "Mean of column  5 : tensor(0.6609)\n",
      "Mean of column  6 : tensor(0.0562)\n",
      "Mean of column  7 : tensor(67.9513)\n",
      "Mean of column  8 : tensor(0.0021)\n",
      "Mean of column  9 : tensor(0.1057)\n",
      "Mean of column  10 : tensor(-0.0828)\n",
      "Mean of column  11 : tensor(79.6878)\n",
      "Mean of column  12 : tensor(0.1736)\n",
      "Mean of column  13 : tensor(93.3167)\n",
      "Mean of column  14 : tensor(-0.0063)\n",
      "Mean of column  15 : tensor(0.0625)\n",
      "Mean of column  16 : tensor(0.0188)\n",
      "Mean of column  17 : tensor(0.)\n",
      "Mean of column  18 : tensor(1.9094)\n",
      "Mean of column  19 : tensor(451.1094)\n"
     ]
    }
   ],
   "source": [
    "for i, (combined_input, target, sample_weight) in enumerate(train_dataloader):\n",
    "    # print(\"combined input shape: \", combined_input.shape)\n",
    "    for j in range(combined_input.shape[1]):\n",
    "        print(\"Mean of column \", j, \":\", combined_input[:, j].mean())\n",
    "    # print(\"Combined Input: \", combined_input[:3, :])\n",
    "    # print(\"Target: \", target)\n",
    "    # print(\"Sample Weight: \", sample_weight)\n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=pd.read_pickle(testdatapath)\n",
    "test_inputdata, test_outputdata=datamaker(testdata)\n",
    "ad_test_inputdata, ad_test_outputdata=additional_datamaker(testdata)\n",
    "test_inputfull=torch.cat((test_inputdata, ad_test_inputdata), dim=1)\n",
    "\n",
    "test_weight=testdata['weightNorm'].to_numpy()\n",
    "test_weight_tensor=torch.tensor(test_weight, dtype=torch.float32)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(test_inputfull, ad_test_outputdata, test_weight_tensor)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=None, shuffle=False)\n",
    "\n",
    "new_model.load_state_dict(torch.load(newmodelsavepath))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
