{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import permutations\n",
    "import torch.nn.functional as F\n",
    "# from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import vector\n",
    "from tqdm.notebook import tqdm\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['event', 'genWeight', 'MET_phi', '1_phi', '1_genPartFlav', '2_phi', '2_genPartFlav', '3_phi', '3_genPartFlav', 'charge_1', 'charge_2', 'charge_3', 'pt_1', 'pt_2', 'pt_3', 'pt_MET', 'eta_1', 'eta_2', 'eta_3', 'mass_1', 'mass_2', 'mass_3', 'deltaphi_12', 'deltaphi_13', 'deltaphi_23', 'deltaphi_1MET', 'deltaphi_2MET', 'deltaphi_3MET', 'deltaphi_1(23)', 'deltaphi_2(13)', 'deltaphi_3(12)', 'deltaphi_MET(12)', 'deltaphi_MET(13)', 'deltaphi_MET(23)', 'deltaphi_1(2MET)', 'deltaphi_1(3MET)', 'deltaphi_2(1MET)', 'deltaphi_2(3MET)', 'deltaphi_3(1MET)', 'deltaphi_3(2MET)', 'deltaeta_12', 'deltaeta_13', 'deltaeta_23', 'deltaeta_1(23)', 'deltaeta_2(13)', 'deltaeta_3(12)', 'deltaR_12', 'deltaR_13', 'deltaR_23', 'deltaR_1(23)', 'deltaR_2(13)', 'deltaR_3(12)', 'pt_123', 'mt_12', 'mt_13', 'mt_23', 'mt_1MET', 'mt_2MET', 'mt_3MET', 'mt_1(23)', 'mt_2(13)', 'mt_3(12)', 'mt_MET(12)', 'mt_MET(13)', 'mt_MET(23)', 'mt_1(2MET)', 'mt_1(3MET)', 'mt_2(1MET)', 'mt_2(3MET)', 'mt_3(1MET)', 'mt_3(2MET)', 'mass_12', 'mass_13', 'mass_23', 'mass_123', 'Mt_tot', 'HNL_CM_angle_with_MET_1', 'HNL_CM_angle_with_MET_2', 'W_CM_angle_to_plane_1', 'W_CM_angle_to_plane_2', 'W_CM_angle_to_plane_with_MET_1', 'W_CM_angle_to_plane_with_MET_2', 'HNL_CM_mass_1', 'HNL_CM_mass_2', 'HNL_CM_mass_with_MET_1', 'HNL_CM_mass_with_MET_2', 'W_CM_angle_12', 'W_CM_angle_13', 'W_CM_angle_23', 'W_CM_angle_1MET', 'W_CM_angle_2MET', 'W_CM_angle_3MET', 'n_tauh', 'norm_mt_1(23)', 'norm_mt_2(13)', 'norm_mt_3(12)', 'norm_mt_MET(12)', 'norm_mt_MET(13)', 'norm_mt_MET(23)', 'norm_mt_1(2MET)', 'norm_mt_1(3MET)', 'norm_mt_2(1MET)', 'norm_mt_2(3MET)', 'norm_mt_3(1MET)', 'norm_mt_3(2MET)', 'norm_mt_12', 'norm_mt_13', 'norm_mt_23'])\n",
      "number of events: 568554\n",
      "dict_keys(['event', 'genWeight', 'MET_phi', '1_phi', '1_genPartFlav', '2_phi', '2_genPartFlav', '3_phi', '3_genPartFlav', 'charge_1', 'charge_2', 'charge_3', 'pt_1', 'pt_2', 'pt_3', 'pt_MET', 'eta_1', 'eta_2', 'eta_3', 'mass_1', 'mass_2', 'mass_3', 'deltaphi_12', 'deltaphi_13', 'deltaphi_23', 'deltaphi_1MET', 'deltaphi_2MET', 'deltaphi_3MET', 'deltaphi_1(23)', 'deltaphi_2(13)', 'deltaphi_3(12)', 'deltaphi_MET(12)', 'deltaphi_MET(13)', 'deltaphi_MET(23)', 'deltaphi_1(2MET)', 'deltaphi_1(3MET)', 'deltaphi_2(1MET)', 'deltaphi_2(3MET)', 'deltaphi_3(1MET)', 'deltaphi_3(2MET)', 'deltaeta_12', 'deltaeta_13', 'deltaeta_23', 'deltaeta_1(23)', 'deltaeta_2(13)', 'deltaeta_3(12)', 'deltaR_12', 'deltaR_13', 'deltaR_23', 'deltaR_1(23)', 'deltaR_2(13)', 'deltaR_3(12)', 'pt_123', 'mt_12', 'mt_13', 'mt_23', 'mt_1MET', 'mt_2MET', 'mt_3MET', 'mt_1(23)', 'mt_2(13)', 'mt_3(12)', 'mt_MET(12)', 'mt_MET(13)', 'mt_MET(23)', 'mt_1(2MET)', 'mt_1(3MET)', 'mt_2(1MET)', 'mt_2(3MET)', 'mt_3(1MET)', 'mt_3(2MET)', 'mass_12', 'mass_13', 'mass_23', 'mass_123', 'Mt_tot', 'HNL_CM_angle_with_MET_1', 'HNL_CM_angle_with_MET_2', 'W_CM_angle_to_plane_1', 'W_CM_angle_to_plane_2', 'W_CM_angle_to_plane_with_MET_1', 'W_CM_angle_to_plane_with_MET_2', 'HNL_CM_mass_1', 'HNL_CM_mass_2', 'HNL_CM_mass_with_MET_1', 'HNL_CM_mass_with_MET_2', 'W_CM_angle_12', 'W_CM_angle_13', 'W_CM_angle_23', 'W_CM_angle_1MET', 'W_CM_angle_2MET', 'W_CM_angle_3MET', 'n_tauh', 'norm_mt_1(23)', 'norm_mt_2(13)', 'norm_mt_3(12)', 'norm_mt_MET(12)', 'norm_mt_MET(13)', 'norm_mt_MET(23)', 'norm_mt_1(2MET)', 'norm_mt_1(3MET)', 'norm_mt_2(1MET)', 'norm_mt_2(3MET)', 'norm_mt_3(1MET)', 'norm_mt_3(2MET)', 'norm_mt_12', 'norm_mt_13', 'norm_mt_23'])\n"
     ]
    }
   ],
   "source": [
    "base_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "full_folder_path = os.path.join(base_path,\"saved_files\", \"fake_data\")\n",
    "# data_df=pd.read_pickle(os.path.join(full_folder_path,\"Aug7_1mil.pkl\"))\n",
    "# with open(os.path.join(full_folder_path,\"Aug10_5mil.pkl\"), 'rb') as f:\n",
    "with open(os.path.join(full_folder_path,\"Aug7_1mil.pkl\"), 'rb') as f:\n",
    "    clean_data_dict = pickle.load(f)\n",
    "print(clean_data_dict.keys())\n",
    "numevents=len(clean_data_dict['2_phi'])\n",
    "print(\"number of events:\",numevents)\n",
    "\n",
    "data_dict=clean_data_dict\n",
    "print(data_dict.keys())\n",
    "\n",
    "data_dict_np={}\n",
    "for key in data_dict.keys():\n",
    "    data_dict_np[key]=np.array(data_dict[key])\n",
    "\n",
    "yaml_name='Aug13run1.yaml'\n",
    "yaml_file_path= os.path.join(base_path, \"fnn_FeatureRegression\", 'yamls', yaml_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events, particles, input features:  (568554, 3, 4)\n",
      "events, particle pairs, output kin. features:  (568554, 3, 5)\n",
      "lepton pair order:  ['1_2', '1_3', '2_3']\n",
      "lepton particle order:  ['1', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "input_data_names_ordered = [\n",
    "    ['MET_phi', 'pt_MET'], \n",
    "    ['1_phi', 'pt_1', 'eta_1', 'mass_1'], \n",
    "    ['2_phi', 'pt_2', 'eta_2', 'mass_2'], \n",
    "    ['3_phi', 'pt_3', 'eta_3', 'mass_3']\n",
    "]\n",
    "input_data_particle_order = ['MET', '1', '2', '3']\n",
    "\n",
    "pair_order = [\"MET_1\", \"MET_2\", \"MET_3\", \"1_2\", \"1_3\", \"2_3\"]\n",
    "used_labels2 = [\n",
    "    ['deltaphi_1MET', 'mt_1MET'], \n",
    "    ['deltaphi_2MET', 'mt_2MET'], \n",
    "    ['deltaphi_3MET', 'mt_3MET'], \n",
    "    ['deltaphi_12', 'deltaeta_12', 'deltaR_12', 'mt_12', 'norm_mt_12'], \n",
    "    ['deltaphi_13', 'deltaeta_13', 'deltaR_13', 'mt_13', 'norm_mt_13'], \n",
    "    ['deltaphi_23', 'deltaeta_23', 'deltaR_23', 'mt_23', 'norm_mt_23']\n",
    "]\n",
    "\n",
    "lepton_input_ordered = input_data_names_ordered[1:]\n",
    "lepton_output_ordered = used_labels2[3:]\n",
    "\n",
    "l_input_shape=(numevents,len(lepton_input_ordered), len(lepton_input_ordered[0]))\n",
    "print(\"events, particles, input features: \",l_input_shape)\n",
    "l_input= np.empty(l_input_shape)\n",
    "\n",
    "for i in range(len(lepton_input_ordered)):\n",
    "    for j, feature in enumerate(lepton_input_ordered[i]):\n",
    "        l_input[:,i,j] = data_dict_np[feature]\n",
    "\n",
    "l_output_shape=(numevents, len(lepton_output_ordered), len(lepton_output_ordered[0]))\n",
    "print(\"events, particle pairs, output kin. features: \",l_output_shape)\n",
    "l_output= np.empty(l_output_shape)\n",
    "\n",
    "for i in range(len(lepton_output_ordered)):\n",
    "    for j, feature in enumerate(lepton_output_ordered[i]):\n",
    "        l_output[:,i,j] = data_dict_np[feature]\n",
    "\n",
    "lepton_pair_order = pair_order[3:]\n",
    "lepton_particle_order = input_data_particle_order[1:]\n",
    "print(\"lepton pair order: \", lepton_pair_order)\n",
    "print(\"lepton particle order: \", lepton_particle_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568554, 3, 8)\n",
      "l_output new shape:  (568554, 3, 13)\n"
     ]
    }
   ],
   "source": [
    "def add_extra_features(data):\n",
    "    p1_pt=data['pt_1']\n",
    "    p2_pt=data['pt_2']\n",
    "    p3_pt=data['pt_3']\n",
    "\n",
    "    p1_phi=data[\"1_phi\"]\n",
    "    p2_phi=data[\"2_phi\"]\n",
    "    p3_phi=data[\"3_phi\"]\n",
    "\n",
    "    p1_eta=data[\"eta_1\"]\n",
    "    p2_eta=data[\"eta_2\"]\n",
    "    p3_eta=data[\"eta_3\"]\n",
    "\n",
    "    p1_mass=data[\"mass_1\"]\n",
    "    p2_mass=data[\"mass_2\"]\n",
    "    p3_mass=data[\"mass_3\"]\n",
    "\n",
    "    particle1=vector.arr({\"pt\": p1_pt, \"phi\": p1_phi, \"eta\": p1_eta, \"mass\": p1_mass})\n",
    "    particle2=vector.arr({\"pt\": p2_pt, \"phi\": p2_phi, \"eta\": p2_eta, \"mass\": p2_mass})\n",
    "    particle3=vector.arr({\"pt\": p3_pt, \"phi\": p3_phi, \"eta\": p3_eta, \"mass\": p3_mass})\n",
    "\n",
    "    p4_mother12=particle1+particle2\n",
    "    p4_mother23=particle2+particle3\n",
    "    p4_mother13=particle1+particle3\n",
    "\n",
    "    pairs=['12','13','23']\n",
    "    motherpairs=[p4_mother12, p4_mother13, p4_mother23]\n",
    "    features_toadd=[ 'mass', 'pt', 'eta' , 'phi',  'px', 'py', 'pz', 'energy']\n",
    "    # features_toadd=[ 'mass', 'pt', 'eta' , 'phi',  'px', 'py', 'pz']\n",
    "\n",
    "    add_feat_size=(len(data['pt_1']), len(pairs), len(features_toadd))\n",
    "    add_feat_array= np.empty(add_feat_size)\n",
    "\n",
    "    for feature in features_toadd:\n",
    "        for i, pair in enumerate(pairs):\n",
    "           add_feat_array[:, i, features_toadd.index(feature)] = getattr(motherpairs[i], feature)\n",
    "    return add_feat_array\n",
    "\n",
    "    \n",
    "    # for i, pair in enumerate(pairs):\n",
    "    #     features_toadd=[ 'mass', 'pt', 'eta' , 'phi',  'px', 'py', 'pz', 'energy']\n",
    "    #     for feature in features_toadd:\n",
    "    #         data['mother_' + feature + '_' + pair] = motherpairs[i].feature\n",
    "    # return data\n",
    "\n",
    "data_conc=add_extra_features(data_dict_np)\n",
    "print(data_conc.shape)\n",
    "# print(data_new.columns)\n",
    "l_output2= np.concatenate((l_output, data_conc), axis=2)\n",
    "print(\"l_output new shape: \",l_output2.shape)\n",
    "\n",
    "n_l_input = l_input\n",
    "n_l_output = l_output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to tensor and adding pairs ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n",
      "torch.Size([568554, 8]) torch.Size([568554, 13])\n"
     ]
    }
   ],
   "source": [
    "linput_tensor = torch.tensor(n_l_input, dtype=torch.float32)\n",
    "llabel_tensor = torch.tensor(n_l_output, dtype=torch.float32)\n",
    "\n",
    "lpairs_data=[]\n",
    "lpairs_labels=[]\n",
    "\n",
    "# lepton_pair_order = ['1_2', '1_3', '2_3']\n",
    "lepton_pair_mapping={(0,1): lepton_pair_order.index('1_2'), (0,2): lepton_pair_order.index('1_3'), (1,2): lepton_pair_order.index('2_3')}\n",
    "\n",
    "for key, value in lepton_pair_mapping.items():\n",
    "    concatonated_data=torch.cat((linput_tensor[:,key[0],:], linput_tensor[:,key[1],:]), dim=1)\n",
    "    lpairs_data.append(concatonated_data)\n",
    "\n",
    "    lpairs_labels.append(llabel_tensor[:,value,:])\n",
    "\n",
    "print(len(lpairs_data), len(lpairs_labels))\n",
    "print(lpairs_data[0].shape, lpairs_labels[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making training data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = []\n",
    "val_data_list = []\n",
    "test_data_list = []\n",
    "train_labels_list = []\n",
    "val_labels_list = []\n",
    "test_labels_list = []\n",
    "\n",
    "for pair_idx in range(len(lpairs_data)):\n",
    "    pair_data = lpairs_data[pair_idx]\n",
    "    pair_labels = lpairs_labels[pair_idx]\n",
    "\n",
    "    train_val_data, test_data, train_val_labels, test_labels = train_test_split(pair_data, pair_labels, test_size=0.2, random_state=42)\n",
    "    train_data, val_data, train_labels, val_labels = train_test_split(train_val_data, train_val_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_data_list.append(train_data)\n",
    "    val_data_list.append(val_data)\n",
    "    test_data_list.append(test_data)\n",
    "    train_labels_list.append(train_labels)\n",
    "    val_labels_list.append(val_labels)\n",
    "    test_labels_list.append(test_labels)\n",
    "\n",
    "class ParticleDataset(Dataset):\n",
    "    def __init__(self, data_list, labels_list):\n",
    "        self.data_list = data_list\n",
    "        self.labels_list = labels_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [data[idx] for data in self.data_list], [label[idx] for label in self.labels_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "class CustomKinematicNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, lenoutput, activation_fn=F.relu, dropout_prob=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - input_size (int): Size of the input layer.\n",
    "        - hidden_layers (list of int): Sizes of each hidden layer.\n",
    "        - lenoutput (int): Size of the output layer.\n",
    "        - activation_fn (callable): Activation function to use.\n",
    "        \"\"\"\n",
    "        super(CustomKinematicNet, self).__init__()\n",
    "        \n",
    "        # Create the list of layers\n",
    "        layers = [nn.Linear(input_size, hidden_layers[0])]\n",
    "        for i in range(len(hidden_layers) - 1):\n",
    "            layers.append(nn.Linear(hidden_layers[i], hidden_layers[i + 1]))\n",
    "        layers.append(nn.Linear(hidden_layers[-1], lenoutput))\n",
    "        \n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.activation_fn = activation_fn\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = self.activation_fn(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        return self.layers[-1](x)\n",
    "\n",
    "# hidden_layer_sizes = [128, 200, 300, 250, 128, 64]\n",
    "lenoutput = l_output2.shape[2]\n",
    "# model = CustomKinematicNet(input_size=10, hidden_layers=hidden_layer_sizes, lenoutput=lenoutput, activation_fn=F.relu)\n",
    "# model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_loss_norm_inverse = [\n",
    "        1.0 / value for value in [\n",
    "            3.1888e+00, 1.8468e+00, 5.8249e+00, 8.0382e+01, 1.1227e-01,\n",
    "            2.7690e+04, 1.0095e+02, 2.7333e+00, 3.6810e+00, 7.6210e+03,\n",
    "            7.4558e+03, 8.9623e+04, 2.8652e+02\n",
    "        ]\n",
    "    ]\n",
    "output_loss_norm_tensor=torch.tensor(output_loss_norm_inverse).to(device)\n",
    "\n",
    "\n",
    "def custom_loss(y_pred, y_true):\n",
    "\n",
    "    # Compute MSE loss for each output individually\n",
    "    mse_loss = F.mse_loss(y_pred, y_true, reduction='none')\n",
    "    \n",
    "    # # Compute RMSE for specific indices and replace in the MSE loss\n",
    "    # indices = [3, 6, 12]\n",
    "    # for idx in indices:\n",
    "    #     RMSE = torch.abs(y_pred[:, idx]**2 - y_true[:, idx]**2) / torch.abs(y_true[:, idx])\n",
    "    #     mask = y_true[:, idx] > 1\n",
    "    #     mse_loss[mask, idx] = RMSE[mask]\n",
    "    \n",
    "    # Calculate average loss of each output\n",
    "    avg_loss_per_output = mse_loss.mean(dim=0)  # Averaging over the batch dimension\n",
    "    \n",
    "    # Normalize the average loss by its maximum loss value\n",
    "    normalized_loss = avg_loss_per_output / avg_loss_per_output.max()\n",
    "    # normalized_loss = avg_loss_per_output * output_loss_norm_tensor\n",
    "    # print(avg_loss_per_output)\n",
    "    # print(normalized_loss)\n",
    "    if normalized_loss.max()/ normalized_loss.min() > 100:\n",
    "        print('Loss is not balanced: ', normalized_loss)\n",
    "    total_loss = normalized_loss.mean()\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "def train_one_epoch(model, data_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for data, labels in data_loader:\n",
    "        data = [d.to(device) for d in data]\n",
    "        labels = [l.to(device) for l in labels]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        total_loss = 0\n",
    "        for i in range(len(data)):\n",
    "            y_pred = model(data[i])\n",
    "            # loss = loss_fn(y_pred, labels[i])\n",
    "            loss = custom_loss(y_pred, labels[i])\n",
    "            total_loss += loss\n",
    "        total_train_loss += total_loss.item()\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(data_loader)\n",
    "    return avg_train_loss\n",
    "\n",
    "\n",
    "def validate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in data_loader:\n",
    "            data = [d.to(device) for d in data]\n",
    "            labels = [l.to(device) for l in labels]\n",
    "\n",
    "            total_loss = 0\n",
    "            for i in range(len(data)):\n",
    "                y_pred = model(data[i])\n",
    "                # loss = loss_fn(y_pred, labels[i])\n",
    "                loss = custom_loss(y_pred, labels[i])                \n",
    "                total_loss += loss\n",
    "            total_val_loss += total_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(data_loader)\n",
    "    return avg_val_loss\n",
    "\n",
    "\n",
    "def test_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in data_loader:\n",
    "            data = [d.to(device) for d in data]\n",
    "            labels = [l.to(device) for l in labels]\n",
    "\n",
    "            total_loss = 0\n",
    "            for i in range(len(data)):\n",
    "                y_pred = model(data[i])\n",
    "                # loss = loss_fn(y_pred, labels[i])\n",
    "                loss = custom_loss(y_pred, labels[i])\n",
    "                total_loss += loss\n",
    "            total_test_loss += total_loss.item()\n",
    "\n",
    "    avg_test_loss = total_test_loss / len(data_loader)\n",
    "    return avg_test_loss\n",
    "\n",
    "def main_training_loop(model, num_epochs, train_data_list, train_labels_list, val_data_list, val_labels_list, optimizer, loss_fn, device, early_stop_patience, batch_size=320):\n",
    "    epochs_no_improve = 0\n",
    "    min_val_loss = np.Inf\n",
    "\n",
    "\n",
    "    train_dataset = ParticleDataset(train_data_list, train_labels_list)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataset = ParticleDataset(val_data_list, val_labels_list)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = ParticleDataset(test_data_list, test_labels_list)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        test_loss = train_one_epoch(model, train_loader, optimizer, device)\n",
    "        # model, data_loader, optimizer, device\n",
    "        # train_loss = train_one_epoch(model, train_data_list, train_labels_list, optimizer, loss_fn, device)\n",
    "        val_loss = validate_model(model, val_loader, device)\n",
    "        # val_loss = validate_model(model, val_loader, loss_fn, device)\n",
    "        # val_loss = validate_model(model, val_data_list, val_labels_list, loss_fn, device)\n",
    "        \n",
    "        if val_loss < min_val_loss:\n",
    "            epochs_no_improve = 0\n",
    "            min_val_loss = val_loss\n",
    "            saved_model = model.state_dict()\n",
    "            # torch.save(model.state_dict(), 'fnn_FeatureRegression/fnn_try4.pt')\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == early_stop_patience:\n",
    "                print('Early stopping!')\n",
    "                return saved_model\n",
    "        if (epoch +1) % 5 == 0:\n",
    "            # test_loss = test_model(model, test_data_list, test_labels_list, loss_fn, device)\n",
    "            # test_loss = test_model(model, test_loader, loss_fn, device)\n",
    "            test_loss = test_model(model, test_loader, device)\n",
    "            print(f\"Epoch [{epoch + 1}], \"\n",
    "            f\"Train Loss: ({test_loss*1000:.4f}), \"\n",
    "                f\"Val Loss: ({val_loss*1000:.4f}), \"\n",
    "                f\"Test Loss: ({test_loss*1000:.4f})\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"Epoch [{epoch + 1}], \"\n",
    "                f\"Train Loss: ({test_loss*1000:.4f}), \"\n",
    "                f\"Val Loss: ({val_loss*1000:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6229f1fa9879452d9afac29daa42712f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is not balanced:  tensor([3.8684e-05, 2.4981e-05, 4.7826e-05, 7.8518e-02, 3.5480e-07, 2.3280e-01,\n",
      "        1.1839e-01, 2.3809e-05, 3.1183e-05, 5.9063e-02, 5.9093e-02, 6.5116e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([4.8264e-05, 3.0216e-05, 5.8871e-05, 7.9991e-02, 4.3244e-07, 2.3190e-01,\n",
      "        1.1330e-01, 2.9142e-05, 3.7919e-05, 5.5761e-02, 5.7283e-02, 6.5731e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.9198e-05, 2.5521e-05, 4.8984e-05, 7.8887e-02, 3.5977e-07, 2.3139e-01,\n",
      "        1.1745e-01, 2.3294e-05, 3.0869e-05, 5.7263e-02, 5.9954e-02, 6.5348e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.6414e-05, 2.3763e-05, 4.6083e-05, 7.7839e-02, 3.0151e-07, 2.2798e-01,\n",
      "        1.1432e-01, 2.2649e-05, 3.0348e-05, 5.6734e-02, 5.7501e-02, 6.5891e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([4.7289e-05, 2.9575e-05, 5.8581e-05, 8.2025e-02, 3.6554e-07, 2.3490e-01,\n",
      "        1.1593e-01, 2.9455e-05, 3.9079e-05, 5.7522e-02, 5.8312e-02, 6.5055e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.6652e-05, 2.3719e-05, 4.6317e-05, 7.7071e-02, 2.9664e-07, 2.2378e-01,\n",
      "        1.1636e-01, 2.2342e-05, 3.0279e-05, 5.7451e-02, 5.8819e-02, 6.6102e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.5575e-05, 2.3317e-05, 4.5849e-05, 7.8340e-02, 2.5295e-07, 2.2634e-01,\n",
      "        1.1388e-01, 2.3380e-05, 3.0591e-05, 5.6675e-02, 5.7250e-02, 6.5977e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([4.5074e-05, 2.8731e-05, 5.7192e-05, 7.8301e-02, 3.2603e-07, 2.2394e-01,\n",
      "        1.1238e-01, 2.9013e-05, 3.9067e-05, 5.6959e-02, 5.5484e-02, 6.6371e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.4682e-05, 2.3019e-05, 4.4670e-05, 7.3086e-02, 2.4905e-07, 2.1702e-01,\n",
      "        1.1289e-01, 2.2628e-05, 3.0554e-05, 5.6034e-02, 5.6918e-02, 6.7010e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.5010e-05, 2.2372e-05, 4.4762e-05, 7.9627e-02, 2.2986e-07, 2.2861e-01,\n",
      "        1.1795e-01, 2.3511e-05, 3.1967e-05, 5.9565e-02, 5.8585e-02, 6.5232e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([4.4295e-05, 2.8074e-05, 5.6554e-05, 8.1156e-02, 2.9095e-07, 2.3285e-01,\n",
      "        1.1948e-01, 2.9154e-05, 3.9530e-05, 5.9218e-02, 6.0491e-02, 6.4644e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.4933e-05, 2.3539e-05, 4.5916e-05, 7.8515e-02, 2.3271e-07, 2.3183e-01,\n",
      "        1.1845e-01, 2.2762e-05, 3.1668e-05, 5.9812e-02, 5.8831e-02, 6.4866e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.2243e-05, 2.1317e-05, 4.2222e-05, 7.5477e-02, 2.0063e-07, 2.1721e-01,\n",
      "        1.1069e-01, 2.2322e-05, 3.0183e-05, 5.5500e-02, 5.5522e-02, 6.6997e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([4.0594e-05, 2.6278e-05, 5.2788e-05, 7.7467e-02, 2.5089e-07, 2.2151e-01,\n",
      "        1.1271e-01, 2.7743e-05, 3.7125e-05, 5.5464e-02, 5.7603e-02, 6.6342e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.2727e-05, 2.1377e-05, 4.2804e-05, 7.3456e-02, 2.0017e-07, 2.1471e-01,\n",
      "        1.1422e-01, 2.2493e-05, 2.9982e-05, 5.7907e-02, 5.6643e-02, 6.6897e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.2161e-05, 2.1296e-05, 4.2408e-05, 7.7437e-02, 1.8887e-07, 2.2842e-01,\n",
      "        1.1664e-01, 2.3301e-05, 3.0562e-05, 5.7991e-02, 5.9132e-02, 6.5160e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([4.0008e-05, 2.5180e-05, 5.1610e-05, 7.9095e-02, 2.2687e-07, 2.2528e-01,\n",
      "        1.1521e-01, 2.8305e-05, 3.8228e-05, 5.9055e-02, 5.6679e-02, 6.5591e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.2564e-05, 2.1765e-05, 4.3237e-05, 7.7602e-02, 1.8877e-07, 2.2680e-01,\n",
      "        1.1674e-01, 2.2657e-05, 3.1088e-05, 5.9049e-02, 5.8186e-02, 6.5319e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.1854e-05, 2.1234e-05, 4.2476e-05, 7.9694e-02, 1.8478e-07, 2.2954e-01,\n",
      "        1.1832e-01, 2.3059e-05, 3.1806e-05, 5.7875e-02, 6.1090e-02, 6.4766e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.9785e-05, 2.5383e-05, 5.2066e-05, 7.8429e-02, 2.2095e-07, 2.2641e-01,\n",
      "        1.1310e-01, 2.8890e-05, 3.8334e-05, 5.6997e-02, 5.6797e-02, 6.5561e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.1557e-05, 2.1532e-05, 4.2471e-05, 7.8229e-02, 1.7990e-07, 2.2738e-01,\n",
      "        1.1734e-01, 2.2515e-05, 3.1235e-05, 5.8605e-02, 5.9383e-02, 6.5087e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.9808e-05, 1.9786e-05, 3.9785e-05, 7.5789e-02, 1.7079e-07, 2.1592e-01,\n",
      "        1.1621e-01, 2.2256e-05, 3.0754e-05, 5.7785e-02, 5.9219e-02, 6.6239e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.9264e-05, 2.4965e-05, 5.1389e-05, 7.9685e-02, 2.1771e-07, 2.2752e-01,\n",
      "        1.1455e-01, 2.9209e-05, 3.9942e-05, 5.7952e-02, 5.7490e-02, 6.5172e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.0166e-05, 2.0684e-05, 4.0877e-05, 7.5861e-02, 1.6697e-07, 2.2168e-01,\n",
      "        1.1553e-01, 2.1901e-05, 3.0932e-05, 5.7970e-02, 5.8337e-02, 6.5738e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.8940e-05, 1.9537e-05, 3.9080e-05, 7.7378e-02, 1.6436e-07, 2.2589e-01,\n",
      "        1.1667e-01, 2.2939e-05, 3.1017e-05, 5.8815e-02, 5.8807e-02, 6.5076e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.7767e-05, 2.4136e-05, 4.9804e-05, 7.9977e-02, 2.0725e-07, 2.3147e-01,\n",
      "        1.1340e-01, 2.8862e-05, 3.8290e-05, 5.7287e-02, 5.7163e-02, 6.4769e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.0156e-05, 2.0149e-05, 4.0482e-05, 7.8151e-02, 1.6331e-07, 2.2815e-01,\n",
      "        1.1705e-01, 2.2806e-05, 3.1098e-05, 5.9940e-02, 5.8047e-02, 6.4816e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.9081e-05, 1.9302e-05, 3.9135e-05, 7.9530e-02, 1.5306e-07, 2.2870e-01,\n",
      "        1.1399e-01, 2.3467e-05, 3.1310e-05, 5.7632e-02, 5.7470e-02, 6.4951e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.7014e-05, 2.4067e-05, 4.9271e-05, 8.0183e-02, 2.0038e-07, 2.2802e-01,\n",
      "        1.1616e-01, 2.9217e-05, 3.9213e-05, 5.8144e-02, 5.9271e-02, 6.4700e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.9412e-05, 1.9977e-05, 3.9877e-05, 7.7168e-02, 1.5544e-07, 2.2511e-01,\n",
      "        1.1523e-01, 2.2770e-05, 3.1493e-05, 5.7630e-02, 5.8716e-02, 6.5190e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.6373e-05, 1.8097e-05, 3.5984e-05, 7.4112e-02, 1.4525e-07, 2.1538e-01,\n",
      "        1.1034e-01, 2.1883e-05, 2.9705e-05, 5.6811e-02, 5.4767e-02, 6.6567e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.4985e-05, 2.2849e-05, 4.6780e-05, 7.7871e-02, 1.8326e-07, 2.2367e-01,\n",
      "        1.1122e-01, 2.8164e-05, 3.8632e-05, 5.6198e-02, 5.6420e-02, 6.5528e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.7448e-05, 1.8997e-05, 3.7703e-05, 7.4766e-02, 1.4443e-07, 2.2215e-01,\n",
      "        1.1044e-01, 2.1685e-05, 3.0271e-05, 5.6809e-02, 5.4859e-02, 6.5877e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.5845e-05, 1.8037e-05, 3.5632e-05, 7.5076e-02, 1.3733e-07, 2.1975e-01,\n",
      "        1.1213e-01, 2.2057e-05, 2.9415e-05, 5.7173e-02, 5.6374e-02, 6.5831e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.4034e-05, 2.2155e-05, 4.5562e-05, 7.7498e-02, 1.7258e-07, 2.2345e-01,\n",
      "        1.1282e-01, 2.8608e-05, 3.8503e-05, 5.8231e-02, 5.6180e-02, 6.5261e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.5923e-05, 1.7824e-05, 3.5470e-05, 7.4411e-02, 1.3426e-07, 2.1857e-01,\n",
      "        1.1311e-01, 2.1456e-05, 2.9145e-05, 5.5771e-02, 5.8760e-02, 6.5862e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.6373e-05, 1.7971e-05, 3.6040e-05, 7.8212e-02, 1.3954e-07, 2.2023e-01,\n",
      "        1.1435e-01, 2.3060e-05, 3.2005e-05, 5.7022e-02, 5.8985e-02, 6.5411e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.2109e-05, 2.1774e-05, 4.3770e-05, 7.6799e-02, 1.6621e-07, 2.2541e-01,\n",
      "        1.1010e-01, 2.7680e-05, 3.7740e-05, 5.6877e-02, 5.4997e-02, 6.5226e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.6123e-05, 1.8439e-05, 3.6348e-05, 7.5372e-02, 1.3402e-07, 2.2066e-01,\n",
      "        1.1396e-01, 2.1651e-05, 3.0718e-05, 5.7516e-02, 5.8073e-02, 6.5436e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.4351e-05, 1.7168e-05, 3.3837e-05, 7.6896e-02, 1.2382e-07, 2.2262e-01,\n",
      "        1.1432e-01, 2.2170e-05, 3.0040e-05, 5.8746e-02, 5.7366e-02, 6.5085e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([3.1406e-05, 2.1219e-05, 4.2932e-05, 7.9118e-02, 1.6110e-07, 2.2588e-01,\n",
      "        1.1659e-01, 2.7838e-05, 3.8503e-05, 5.9870e-02, 5.8770e-02, 6.4383e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.4638e-05, 1.7417e-05, 3.4329e-05, 7.5660e-02, 1.2244e-07, 2.2251e-01,\n",
      "        1.1711e-01, 2.1427e-05, 3.0796e-05, 6.0906e-02, 5.8027e-02, 6.4826e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.3456e-05, 1.6417e-05, 3.2616e-05, 7.6581e-02, 1.1743e-07, 2.2024e-01,\n",
      "        1.1479e-01, 2.1747e-05, 3.0241e-05, 5.8891e-02, 5.7896e-02, 6.5161e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.9932e-05, 2.0385e-05, 4.1127e-05, 7.6418e-02, 1.4434e-07, 2.2157e-01,\n",
      "        1.1119e-01, 2.7287e-05, 3.8924e-05, 5.7170e-02, 5.6225e-02, 6.5244e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.3190e-05, 1.6618e-05, 3.2455e-05, 7.2548e-02, 1.1373e-07, 2.0965e-01,\n",
      "        1.1401e-01, 2.1345e-05, 2.9890e-05, 5.7167e-02, 5.8819e-02, 6.6325e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.2592e-05, 1.5973e-05, 3.1492e-05, 7.5476e-02, 1.1112e-07, 2.1751e-01,\n",
      "        1.1128e-01, 2.1946e-05, 3.0704e-05, 5.7999e-02, 5.5442e-02, 6.5687e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.9399e-05, 2.0191e-05, 4.0619e-05, 7.7266e-02, 1.3527e-07, 2.2340e-01,\n",
      "        1.1032e-01, 2.7558e-05, 3.8457e-05, 5.5303e-02, 5.7474e-02, 6.4999e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.2861e-05, 1.6693e-05, 3.2362e-05, 7.5555e-02, 1.0531e-07, 2.1971e-01,\n",
      "        1.0867e-01, 2.1090e-05, 2.9933e-05, 5.4914e-02, 5.5908e-02, 6.5740e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.2140e-05, 1.6448e-05, 3.1610e-05, 7.5330e-02, 1.0348e-07, 2.2766e-01,\n",
      "        1.1238e-01, 2.2666e-05, 3.0343e-05, 5.7446e-02, 5.7368e-02, 6.4396e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.9275e-05, 1.9695e-05, 4.0025e-05, 7.8385e-02, 1.3059e-07, 2.2330e-01,\n",
      "        1.1303e-01, 2.8929e-05, 3.8079e-05, 5.7618e-02, 5.8131e-02, 6.4581e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.2940e-05, 1.6740e-05, 3.2503e-05, 7.4626e-02, 1.0274e-07, 2.1572e-01,\n",
      "        1.1413e-01, 2.2189e-05, 3.0672e-05, 5.7830e-02, 5.8747e-02, 6.5430e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.1874e-05, 1.5863e-05, 3.0837e-05, 7.6852e-02, 9.5654e-08, 2.2056e-01,\n",
      "        1.1387e-01, 2.2822e-05, 3.1545e-05, 5.9093e-02, 5.7479e-02, 6.4813e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.7338e-05, 1.8988e-05, 3.7627e-05, 7.6960e-02, 1.1900e-07, 2.1813e-01,\n",
      "        1.1359e-01, 2.8040e-05, 3.9161e-05, 5.8451e-02, 5.8109e-02, 6.4908e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.1764e-05, 1.6524e-05, 3.1320e-05, 7.5029e-02, 9.9103e-08, 2.2022e-01,\n",
      "        1.1525e-01, 2.2067e-05, 3.1271e-05, 5.9815e-02, 5.8134e-02, 6.4729e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.0722e-05, 1.5450e-05, 2.9438e-05, 7.5970e-02, 8.6934e-08, 2.2084e-01,\n",
      "        1.1249e-01, 2.2455e-05, 3.1226e-05, 5.7540e-02, 5.7864e-02, 6.4809e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.7231e-05, 1.8895e-05, 3.7438e-05, 7.8739e-02, 1.1206e-07, 2.2228e-01,\n",
      "        1.0911e-01, 2.8676e-05, 3.9603e-05, 5.7113e-02, 5.5238e-02, 6.4778e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.0226e-05, 1.5082e-05, 2.8709e-05, 7.1375e-02, 8.4336e-08, 2.1124e-01,\n",
      "        1.1219e-01, 2.1539e-05, 2.9796e-05, 5.7434e-02, 5.7597e-02, 6.5862e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.0023e-05, 1.4282e-05, 2.7765e-05, 7.5487e-02, 7.8479e-08, 2.1386e-01,\n",
      "        1.1044e-01, 2.2204e-05, 2.9718e-05, 5.5146e-02, 5.8365e-02, 6.5631e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.4477e-05, 1.7594e-05, 3.4031e-05, 7.4673e-02, 9.9918e-08, 2.1446e-01,\n",
      "        1.1024e-01, 2.7094e-05, 3.7032e-05, 5.6205e-02, 5.7428e-02, 6.5388e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([1.9798e-05, 1.5352e-05, 2.8470e-05, 7.3969e-02, 8.1050e-08, 2.2100e-01,\n",
      "        1.1577e-01, 2.1727e-05, 3.0767e-05, 5.9056e-02, 5.9892e-02, 6.4357e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([1.8630e-05, 1.4373e-05, 2.6593e-05, 7.4039e-02, 7.0930e-08, 2.1864e-01,\n",
      "        1.1058e-01, 2.1840e-05, 3.0354e-05, 5.7717e-02, 5.6174e-02, 6.5008e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.5052e-05, 1.7633e-05, 3.4459e-05, 7.7947e-02, 9.1120e-08, 2.1995e-01,\n",
      "        1.1125e-01, 2.8778e-05, 3.9310e-05, 5.7305e-02, 5.7714e-02, 6.4523e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([1.8920e-05, 1.4866e-05, 2.7240e-05, 7.2956e-02, 7.3615e-08, 2.1335e-01,\n",
      "        1.1133e-01, 2.1722e-05, 3.0208e-05, 5.6143e-02, 5.8517e-02, 6.5474e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([1.8002e-05, 1.3747e-05, 2.5370e-05, 7.4096e-02, 6.5148e-08, 2.1444e-01,\n",
      "        1.0920e-01, 2.1906e-05, 2.9987e-05, 5.7078e-02, 5.5664e-02, 6.5450e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.3850e-05, 1.7911e-05, 3.3446e-05, 7.6497e-02, 8.4164e-08, 2.2719e-01,\n",
      "        1.1064e-01, 2.8202e-05, 3.8640e-05, 5.8372e-02, 5.6312e-02, 6.3719e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([1.8458e-05, 1.4103e-05, 2.6132e-05, 7.2914e-02, 6.5758e-08, 2.1154e-01,\n",
      "        1.1120e-01, 2.1739e-05, 3.0215e-05, 5.7426e-02, 5.7352e-02, 6.5547e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([1.7276e-05, 1.3718e-05, 2.4622e-05, 7.3072e-02, 6.0403e-08, 2.2147e-01,\n",
      "        1.1228e-01, 2.1810e-05, 3.0904e-05, 5.6885e-02, 5.9325e-02, 6.4259e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.2862e-05, 1.6813e-05, 3.1481e-05, 7.7192e-02, 7.6196e-08, 2.2530e-01,\n",
      "        1.0961e-01, 2.8117e-05, 3.8359e-05, 5.6542e-02, 5.7382e-02, 6.3874e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([1.7475e-05, 1.3833e-05, 2.4906e-05, 7.1888e-02, 6.0584e-08, 2.1826e-01,\n",
      "        1.1174e-01, 2.1664e-05, 3.0874e-05, 5.7368e-02, 5.8252e-02, 6.4673e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([1.7491e-05, 1.3611e-05, 2.4598e-05, 7.6153e-02, 5.5169e-08, 2.2286e-01,\n",
      "        1.1304e-01, 2.2620e-05, 3.1450e-05, 5.9490e-02, 5.7795e-02, 6.3874e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([2.2027e-05, 1.6010e-05, 2.9982e-05, 7.7382e-02, 6.7585e-08, 2.2169e-01,\n",
      "        1.1190e-01, 2.7789e-05, 3.8872e-05, 5.7862e-02, 5.8727e-02, 6.3836e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Loss is not balanced:  tensor([1.7535e-05, 1.4197e-05, 2.5090e-05, 7.3758e-02, 5.6092e-08, 2.2346e-01,\n",
      "        1.1340e-01, 2.1950e-05, 3.1115e-05, 5.8919e-02, 5.8714e-02, 6.3803e-01,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m l2_reg_strength \u001b[39m=\u001b[39m \u001b[39m1e-4\u001b[39m\n\u001b[1;32m     37\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(curr_model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.003\u001b[39m, weight_decay\u001b[39m=\u001b[39ml2_reg_strength)\n\u001b[0;32m---> 38\u001b[0m curr_saved_model \u001b[39m=\u001b[39m main_training_loop(curr_model, num_epochs, train_data_list, train_labels_list, val_data_list, val_labels_list, optimizer, loss_fn, device, early_stop_patience, batch_size\u001b[39m=\u001b[39;49mbatch_size)\n\u001b[1;32m     39\u001b[0m saved_models\u001b[39m.\u001b[39mappend(curr_saved_model)\n",
      "Cell \u001b[0;32mIn[44], line 116\u001b[0m, in \u001b[0;36mmain_training_loop\u001b[0;34m(model, num_epochs, train_data_list, train_labels_list, val_data_list, val_labels_list, optimizer, loss_fn, device, early_stop_patience, batch_size)\u001b[0m\n\u001b[1;32m    113\u001b[0m test_loader \u001b[39m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    115\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m--> 116\u001b[0m     test_loss \u001b[39m=\u001b[39m train_one_epoch(model, train_loader, optimizer, device)\n\u001b[1;32m    117\u001b[0m     \u001b[39m# model, data_loader, optimizer, device\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# train_loss = train_one_epoch(model, train_data_list, train_labels_list, optimizer, loss_fn, device)\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     val_loss \u001b[39m=\u001b[39m validate_model(model, val_loader, device)\n",
      "Cell \u001b[0;32mIn[44], line 41\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, data_loader, optimizer, device)\u001b[0m\n\u001b[1;32m     38\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     39\u001b[0m total_train_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[39mfor\u001b[39;00m data, labels \u001b[39min\u001b[39;00m data_loader:\n\u001b[1;32m     42\u001b[0m     data \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data]\n\u001b[1;32m     43\u001b[0m     labels \u001b[39m=\u001b[39m [l\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m labels]\n",
      "File \u001b[0;32m~/.conda/envs/Dmitri-conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/Dmitri-conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/Dmitri-conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/Dmitri-conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[42], line 31\u001b[0m, in \u001b[0;36mParticleDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m [data[idx] \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_list], [label[idx] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels_list]\n",
      "Cell \u001b[0;32mIn[42], line 31\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m [data[idx] \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_list], [label[idx] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels_list]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=10000\n",
    "num_epochs = 100000\n",
    "early_stop_patience = 15\n",
    "loss_fn = nn.MSELoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "saved_models = []\n",
    "\n",
    "with open(yaml_file_path, 'r') as yaml_file:\n",
    "    loaded_data = yaml.load(yaml_file, Loader=yaml.SafeLoader)\n",
    "\n",
    "# Accessing data from the loaded dictionary\n",
    "hidden_layers_list_loaded = loaded_data['hidden_layers_list']\n",
    "activation_fn_names_loaded = loaded_data['activation_fn_list']\n",
    "\n",
    "# Map function names back to their actual functions\n",
    "activation_fn_mapping = {\n",
    "    'relu': F.relu,\n",
    "    'sigmoid': F.sigmoid,\n",
    "    'tanh': F.tanh\n",
    "}\n",
    "\n",
    "# Convert function names to actual functions\n",
    "activation_fn_list_loaded = [activation_fn_mapping[name] for name in activation_fn_names_loaded]\n",
    "\n",
    "hidden_layers_list = hidden_layers_list_loaded\n",
    "activation_fn_list = activation_fn_list_loaded\n",
    "\n",
    "pbar = tqdm(hidden_layers_list, total=len(hidden_layers_list))\n",
    "\n",
    "for i, hidden_layers_curr in enumerate(pbar):\n",
    "    pbar.set_description(f\"model [{i+1}/{len(hidden_layers_list)}]\")\n",
    "    # print(f\"[{i+1}/{len(hidden_layers_list)}] Hidden Layers: {hidden_layers_curr}\")\n",
    "    curr_model= CustomKinematicNet(input_size=8, hidden_layers=hidden_layers_curr, lenoutput=lenoutput, activation_fn=F.sigmoid)\n",
    "    curr_model.to(device)\n",
    "    l2_reg_strength = 1e-4\n",
    "    optimizer = torch.optim.Adam(curr_model.parameters(), lr=0.003, weight_decay=l2_reg_strength)\n",
    "    curr_saved_model = main_training_loop(curr_model, num_epochs, train_data_list, train_labels_list, val_data_list, val_labels_list, optimizer, loss_fn, device, early_stop_patience, batch_size=batch_size)\n",
    "    saved_models.append(curr_saved_model)\n",
    "\n",
    "\n",
    "\n",
    "# Format: (MSE, RMSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
