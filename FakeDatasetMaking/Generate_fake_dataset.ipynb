{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code defines and utilizes the `Data_generator` class to generate synthetic data for a physics experiment. The program then cleans up the data by removing outliers and subsequently stores the clean data in a pickle file. \n",
    "\n",
    "## Data Generation\n",
    "\n",
    "`Data_generator` is the main part of this script and is initialized with two parameters: the number of events (`numevents`) and a boolean indicating whether the generated data should be normalized or not. The synthetic data is a representation of the result of physics events involving multiple particles, where each particle is characterized by different properties such as `eta`, `mass`, `phi`, `pt`, `charge`, and `genPartFlav`.\n",
    "\n",
    "Upon initialization, `Data_generator` configures a series of functions and input variables, which are then utilized in the `generate_fake_data` method to generate synthetic data. \n",
    "\n",
    "The `generate_fake_data` method starts by creating a dictionary, `data`, with keys for each variable and empty lists as values. It then generates random data for these variables using relevant statistical distributions which are based on the physical properties being simulated. \n",
    "\n",
    "After the data has been generated, `Data_generator` includes an optional step of renaming and reordering keys in the dictionary in a more standard format, before returning the data.\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "After generating the data, outliers are removed using the `remove_outliers` function. This function uses the limits defined in a YAML file to identify and remove the outliers in the data. \n",
    "\n",
    "## Data Storage\n",
    "\n",
    "Once the outliers have been removed, the data is then stored as a pickle file at a specified location for later use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "sys.path.append('../utils/')\n",
    "from DD_data_extractor_git import Data_generator\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 19 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting results: 100%|██████████| 19/19 [00:00<00:00, 21.17it/s]\n",
      "Applying functions: 50it [01:46,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "num_events = 2000000\n",
    "Data_generator1 = Data_generator(num_events, normalize=True)\n",
    "data_dict=Data_generator1.getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000\n",
      "[ 2.86729962  1.69881736  2.71736027  1.30041138 -3.0487028  -2.94071761\n",
      " -1.4018133   3.08674221 -1.90163112  2.47294006]\n"
     ]
    }
   ],
   "source": [
    "print(len(data_dict['1_phi']))\n",
    "print(data_dict['1_phi'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_length = len(next(iter(data_dict.values())))\n",
    "for feature_name, values in data_dict.items():\n",
    "    if len(values) != reference_length:\n",
    "       print(f\"Feature '{feature_name}' has {len(values)} values, expected {reference_length}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['event', 'genWeight', 'MET_phi', '1_phi', '1_genPartFlav', '2_phi', '2_genPartFlav', '3_phi', '3_genPartFlav', 'charge_1', 'charge_2', 'charge_3', 'pt_1', 'pt_2', 'pt_3', 'pt_MET', 'eta_1', 'eta_2', 'eta_3', 'mass_1', 'mass_2', 'mass_3', 'deltaphi_12', 'deltaphi_13', 'deltaphi_23', 'deltaphi_1MET', 'deltaphi_2MET', 'deltaphi_3MET', 'deltaphi_1(23)', 'deltaphi_2(13)', 'deltaphi_3(12)', 'deltaphi_MET(12)', 'deltaphi_MET(13)', 'deltaphi_MET(23)', 'deltaphi_1(2MET)', 'deltaphi_1(3MET)', 'deltaphi_2(1MET)', 'deltaphi_2(3MET)', 'deltaphi_3(1MET)', 'deltaphi_3(2MET)', 'deltaeta_12', 'deltaeta_13', 'deltaeta_23', 'deltaeta_1(23)', 'deltaeta_2(13)', 'deltaeta_3(12)', 'deltaR_12', 'deltaR_13', 'deltaR_23', 'deltaR_1(23)', 'deltaR_2(13)', 'deltaR_3(12)', 'pt_123', 'mt_12', 'mt_13', 'mt_23', 'mt_1MET', 'mt_2MET', 'mt_3MET', 'mt_1(23)', 'mt_2(13)', 'mt_3(12)', 'mt_MET(12)', 'mt_MET(13)', 'mt_MET(23)', 'mt_1(2MET)', 'mt_1(3MET)', 'mt_2(1MET)', 'mt_2(3MET)', 'mt_3(1MET)', 'mt_3(2MET)', 'mass_12', 'mass_13', 'mass_23', 'mass_123', 'Mt_tot', 'HNL_CM_angle_with_MET_1', 'HNL_CM_angle_with_MET_2', 'W_CM_angle_to_plane_1', 'W_CM_angle_to_plane_2', 'W_CM_angle_to_plane_with_MET_1', 'W_CM_angle_to_plane_with_MET_2', 'HNL_CM_mass_1', 'HNL_CM_mass_2', 'HNL_CM_mass_with_MET_1', 'HNL_CM_mass_with_MET_2', 'W_CM_angle_12', 'W_CM_angle_13', 'W_CM_angle_23', 'W_CM_angle_1MET', 'W_CM_angle_2MET', 'W_CM_angle_3MET', 'n_tauh', 'norm_mt_1(23)', 'norm_mt_2(13)', 'norm_mt_3(12)', 'norm_mt_MET(12)', 'norm_mt_MET(13)', 'norm_mt_MET(23)', 'norm_mt_1(2MET)', 'norm_mt_1(3MET)', 'norm_mt_2(1MET)', 'norm_mt_2(3MET)', 'norm_mt_3(1MET)', 'norm_mt_3(2MET)', 'norm_mt_12', 'norm_mt_13', 'norm_mt_23'])\n",
      "1137532\n"
     ]
    }
   ],
   "source": [
    "def compute_percentiles_from_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        raw_data_dict = pickle.load(f)\n",
    "    \n",
    "    numeric_data_dict = {k: v for k, v in raw_data_dict.items() if (k not in dontremove_outliers) and np.issubdtype(type(v[0]), np.number)}\n",
    "\n",
    "    # Compute the required percentiles for each numeric feature\n",
    "    lower_percentiles = {k: np.percentile(v, 0.03) for k, v in numeric_data_dict.items()}\n",
    "    upper_percentiles = {k: np.percentile(v, 99.7) for k, v in numeric_data_dict.items()}\n",
    "\n",
    "    return lower_percentiles, upper_percentiles\n",
    "\n",
    "def remove_outliers(data, lower_percentiles, upper_percentiles):\n",
    "    outlier_mask = np.zeros(len(next(iter(data.values()))), dtype=bool)\n",
    "    for feature_name, values in data.items():\n",
    "        if (feature_name not in dontremove_outliers) and (feature_name in lower_percentiles):\n",
    "            lower_value = lower_percentiles[feature_name]\n",
    "            upper_value = upper_percentiles[feature_name]\n",
    "            feature_outlier_mask = (np.array(values) < lower_value) | (np.array(values) > upper_value)\n",
    "            outlier_mask |= feature_outlier_mask  # update the outlier mask\n",
    "    \n",
    "    # Remove rows with outliers from all features in the data dictionary\n",
    "    cleaned_data = {k: np.array(v)[~outlier_mask].tolist() for k, v in data.items()}\n",
    "    return cleaned_data\n",
    "\n",
    "base_path = os.path.dirname(os.getcwd())\n",
    "raw_data_pickle_file = os.path.join(base_path, 'saved_files', 'extracted_data', 'TEST10_data_Aug3')\n",
    "dontremove_outliers=['event', 'genWeight', 'MET_phi', '1_phi', '1_genPartFlav', '2_phi', '2_genPartFlav', '3_phi', '3_genPartFlav', 'charge_1', 'charge_2', 'charge_3', 'pt_1', 'pt_2', 'pt_3', 'pt_MET', 'eta_1', 'eta_2', 'eta_3', 'mass_1', 'mass_2', 'mass_3']\n",
    "lower_percentiles, upper_percentiles = compute_percentiles_from_pickle(raw_data_pickle_file)\n",
    "\n",
    "data_dictcopy = deepcopy(data_dict)\n",
    "data_dict_removed_outliers2 = remove_outliers(data_dictcopy, lower_percentiles, upper_percentiles)\n",
    "\n",
    "print(data_dict_removed_outliers2.keys())\n",
    "print(len(data_dict_removed_outliers2['mass_12']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83.66990839135985, 186.38373934681758, 149.23723598465253, 104.73620019765548, 79.78720041567763, 115.19047244685707, 103.55794033964735, 187.1008249688647, 268.14500854362166, 98.01004739849058, 190.66351109704678, 90.32116793823182, 143.83902090183196, 224.52883185117742, 112.5204179161392, 190.32785788163682, 34.752393649485875, 141.03692309729942, 77.38751946051595, 95.7951877022242, 87.70633372026211, 126.31470007635605, 47.817641081091445, 56.45543058611864, 132.18374784966355, 71.92480693368006, 109.88823039285298, 179.88182028553385, 232.41017498298265, 64.9818492372619]\n"
     ]
    }
   ],
   "source": [
    "print(data_dict_removed_outliers2['mass_12'][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['event', 'genWeight', 'MET_phi', '1_phi', '1_genPartFlav', '2_phi', '2_genPartFlav', '3_phi', '3_genPartFlav', 'charge_1', 'charge_2', 'charge_3', 'pt_1', 'pt_2', 'pt_3', 'pt_MET', 'eta_1', 'eta_2', 'eta_3', 'mass_1', 'mass_2', 'mass_3', 'deltaphi_12', 'deltaphi_13', 'deltaphi_23', 'deltaphi_1MET', 'deltaphi_2MET', 'deltaphi_3MET', 'deltaphi_1(23)', 'deltaphi_2(13)', 'deltaphi_3(12)', 'deltaphi_MET(12)', 'deltaphi_MET(13)', 'deltaphi_MET(23)', 'deltaphi_1(2MET)', 'deltaphi_1(3MET)', 'deltaphi_2(1MET)', 'deltaphi_2(3MET)', 'deltaphi_3(1MET)', 'deltaphi_3(2MET)', 'deltaeta_12', 'deltaeta_13', 'deltaeta_23', 'deltaeta_1(23)', 'deltaeta_2(13)', 'deltaeta_3(12)', 'deltaR_12', 'deltaR_13', 'deltaR_23', 'deltaR_1(23)', 'deltaR_2(13)', 'deltaR_3(12)', 'pt_123', 'mt_12', 'mt_13', 'mt_23', 'mt_1MET', 'mt_2MET', 'mt_3MET', 'mt_1(23)', 'mt_2(13)', 'mt_3(12)', 'mt_MET(12)', 'mt_MET(13)', 'mt_MET(23)', 'mt_1(2MET)', 'mt_1(3MET)', 'mt_2(1MET)', 'mt_2(3MET)', 'mt_3(1MET)', 'mt_3(2MET)', 'mass_12', 'mass_13', 'mass_23', 'mass_123', 'Mt_tot', 'HNL_CM_angle_with_MET_1', 'HNL_CM_angle_with_MET_2', 'W_CM_angle_to_plane_1', 'W_CM_angle_to_plane_2', 'W_CM_angle_to_plane_with_MET_1', 'W_CM_angle_to_plane_with_MET_2', 'HNL_CM_mass_1', 'HNL_CM_mass_2', 'HNL_CM_mass_with_MET_1', 'HNL_CM_mass_with_MET_2', 'W_CM_angle_12', 'W_CM_angle_13', 'W_CM_angle_23', 'W_CM_angle_1MET', 'W_CM_angle_2MET', 'W_CM_angle_3MET', 'n_tauh', 'norm_mt_1(23)', 'norm_mt_2(13)', 'norm_mt_3(12)', 'norm_mt_MET(12)', 'norm_mt_MET(13)', 'norm_mt_MET(23)', 'norm_mt_1(2MET)', 'norm_mt_1(3MET)', 'norm_mt_2(1MET)', 'norm_mt_2(3MET)', 'norm_mt_3(1MET)', 'norm_mt_3(2MET)', 'norm_mt_12', 'norm_mt_13', 'norm_mt_23'])\n",
      "1137532\n"
     ]
    }
   ],
   "source": [
    "base_path = os.path.dirname(os.getcwd())\n",
    "folder = \"fake_data\"\n",
    "\n",
    "full_folder_path = os.path.join(base_path,\"saved_files\", folder)\n",
    "\n",
    "os.makedirs(full_folder_path, exist_ok=True)\n",
    "\n",
    "filename = \"Aug10_2mil.pkl\"\n",
    "\n",
    "full_file_path = os.path.join(full_folder_path, filename)\n",
    "\n",
    "with open(full_file_path, 'wb') as f:\n",
    "    pickle.dump(data_dict_removed_outliers2, f)\n",
    "\n",
    "\n",
    "print(data_dict_removed_outliers2.keys())\n",
    "print(len(data_dict_removed_outliers2['mass_12']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
