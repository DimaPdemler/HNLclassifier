{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code defines and utilizes the `Data_generator` class to generate synthetic data for a physics experiment. The program then cleans up the data by removing outliers and subsequently stores the clean data in a pickle file. \n",
    "\n",
    "## Data Generation\n",
    "\n",
    "`Data_generator` is the heart of this script and is initialized with two parameters: the number of events (`numevents`) and a boolean indicating whether the generated data should be normalized or not. The synthetic data is a representation of the result of physics events involving multiple particles, where each particle is characterized by different properties such as `eta`, `mass`, `phi`, `pt`, `charge`, and `genPartFlav`.\n",
    "\n",
    "Upon initialization, `Data_generator` configures a series of functions and input variables, which are then utilized in the `generate_fake_data` method to generate synthetic data. \n",
    "\n",
    "The `generate_fake_data` method starts by creating a dictionary, `data`, with keys for each variable and empty lists as values. It then generates random data for these variables using relevant statistical distributions which are based on the physical properties being simulated. \n",
    "\n",
    "After the data has been generated, `Data_generator` includes an optional step of renaming and reordering keys in the dictionary in a more standard format, before returning the data.\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "After generating the data, outliers are removed using the `remove_outliers` function. This function uses the limits defined in a YAML file to identify and remove the outliers in the data. \n",
    "\n",
    "## Data Storage\n",
    "\n",
    "Once the outliers have been removed, the data is then stored as a pickle file at a specified location for later use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "sys.path.append('../utils/')\n",
    "from DD_data_extractor_git import Data_generator, remove_all_outliers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_events = 100\n",
    "Data_generator1 = Data_generator(num_events, normalize=True)\n",
    "data_dict=Data_generator1.getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml_file(filename):\n",
    "    with open(filename, 'r') as stream:\n",
    "        try:\n",
    "            data = yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "    return data\n",
    "\n",
    "limits = read_yaml_file('GenerateDataClean.yaml')\n",
    "\n",
    "def remove_outliers(data, limits):\n",
    "    outlier_mask = np.zeros(data[next(iter(data))].shape, dtype=bool)  # initially no outliers\n",
    "\n",
    "    do_not_cut = limits.get('do_not_cut', [])\n",
    "    cuts = limits.get('cuts', {})\n",
    "\n",
    "    for feature_name in data.keys():\n",
    "        if feature_name in do_not_cut:\n",
    "            continue  # do not change the outlier mask\n",
    "\n",
    "        feature_limits = cuts.get(feature_name)\n",
    "        if feature_limits is not None:\n",
    "            lower_limit, upper_limit = feature_limits.get('lower_percentile', 0.03), feature_limits.get('upper_percentile', 99.7)\n",
    "        else:\n",
    "            lower_limit, upper_limit = 0.03, 99.7\n",
    "\n",
    "        lower_value, upper_value = np.percentile(data[feature_name], [lower_limit, upper_limit])\n",
    "        feature_outlier_mask = (data[feature_name] < lower_value) | (data[feature_name] > upper_value)\n",
    "        outlier_mask |= feature_outlier_mask  # update the outlier mask\n",
    "\n",
    "    # remove outliers from all features\n",
    "    for feature_name in data.keys():\n",
    "        data[feature_name] = data[feature_name][~outlier_mask]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "data_dict_removed_outliers2 = deepcopy(data_dict)\n",
    "data_dict_removed_outliers2 = remove_outliers(data_dict_removed_outliers2, limits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/ddemler/dmitri_stuff/\"\n",
    "folder = \"saved_models/gnn/raw_data_fake\"\n",
    "\n",
    "full_folder_path = os.path.join(base_path, folder)\n",
    "\n",
    "os.makedirs(full_folder_path, exist_ok=True)\n",
    "\n",
    "filename = \"data_dict_removed_outliersAug3.pkl\"\n",
    "\n",
    "full_file_path = os.path.join(full_folder_path, filename)\n",
    "\n",
    "with open(full_file_path, 'wb') as f:\n",
    "    pickle.dump(data_dict_removed_outliers2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdpath=\"/home/ddemler/dmitri_stuff/\"\n",
    "\n",
    "train = pd.read_pickle(cdpath + 'extracted_data/TEST10_v4_train_DD2')\n",
    "val = pd.read_pickle(cdpath + 'extracted_data/TEST10_v4_val_DD2')\n",
    "test = pd.read_pickle(cdpath + 'extracted_data/TEST10_v4_test_DD2')\n",
    "df=pd.concat([train,val,test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
